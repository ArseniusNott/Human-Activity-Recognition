})
classnames <- sapply(training[1:4, ], function(x) {
if (class(x) != factor) {
return(name(x) = class(x))
}
})
return("shu" = class(x))
classnames <- sapply(training[1:4, ], function(x) {
if (class(x) != factor) {
return("shu" = class(x))
}
})
names(classnames[1])
classnames <- sapply(training[1:4, ], function(x) {
if (class(x) != factor) {
toReturn <- class(x)
names(toReturn) <- names(x)
return(toReturn)
}
})
classnames <- sapply(training[1:4, ], function(x) {
if (! is.factor(x)) {
toReturn <- class(x)
names(toReturn) <- names(x)
return(toReturn)
}
})
View(classnames)
classnames <- sapply(training[1:4, ], function(x) {
if (! is.factor(x)) {
toReturn <- class(x)
names(toReturn) <- names(x)
return(toReturn)
} else {
return(NULL)
}
})
install.packages(rattle)
library(rpart.plot)
fancyRpartPlot(train$finalModel)
install.packages(fancyRpartPlot)
install.packages("fancyRpartPlot")
library(rpart.plot)
fancyRpartPlot(train$finalModel)
install.packages("rattle")
library(rpart.plot)
fancyRpartPlot(train$finalModel)
rpart.plot(train$finalModel)
install.packages("pgmm")
# Q3.
# Load the olive oil data using the commands:
library(pgmm)
data(olive)
olive = olive[,-1]
# Q3.
# Load the olive oil data using the commands:
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
head(olive)
# ATTEMPT
train <- train(Area ~ .,
data = olive,
method = "tree")
# ATTEMPT
train <- train(Area ~ .,
data = olive,
method = "rpart")
predict(train, newdata = newdata)
olive$Area
# Q4.
# Load the South Africa Heart Disease Data and create training and test sets
# with the following code:
library(ElemStatLearn)
install.packages("ElemStatLearn")
# Q4.
# Load the South Africa Heart Disease Data and create training and test sets
# with the following code:
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
# Then set the seed to 13234 and fit a logistic regression model (method="glm",
# be sure to specify family="binomial") with Coronary Heart Disease (chd) as
# the outcome and age at onset, current alcohol consumption, obesity levels,
# cumulative tabacco, type-A behavior, and low density lipoprotein cholesterol
# as predictors. Calculate the misclassification rate for your model using this
# function and a prediction on the "response" scale:
missClass = function(values, prediction) {
sum(((prediction > 0.5)*1) != values) / length(values)
}
# ATTEMPT
set.seed(13234)
str(train)
str(trainSA)
train <- train(chd ~ age + alcohol + obesity + tobacco +typea + ldl,
method = "glm",
family = "binomial")
pred <- predict(testSA$chd, predict(train, trainSA$chd))
pred <- confusionMatrix(testSA$chd, predict(train, trainSA$chd))
train <- train(chd ~ age + alcohol + obesity + tobacco +typea + ldl,
data = trainSA,
method = "glm",
family = "binomial")
pred <- confusionMatrix(testSA$chd, predict(train, trainSA$chd))
pred <- confusionMatrix(testSA$chd,
predict(train,
trainSA[, c("age", "alcohol", "obesity",
"tobacco", "typea", "ldl")]))
pred <- confusionMatrix(testSA$chd,
predict(train,
testSA[, c("age", "alcohol", "obesity",
"tobacco", "typea", "ldl")]))
pred <- confusionMatrix(testSA$chd,
predict(train,
testSA))
train <- train(chd ~ age + alcohol + obesity + tobacco +typea + ldl,
data = trainSA,
method = "glm",
family = "binomial")
trainSA$chd
train <- train(I(factor(chd)) ~ age + alcohol + obesity + tobacco +typea + ldl,
data = trainSA,
method = "glm",
family = "binomial")
pred <- confusionMatrix(testSA$chd, predict(train, testSA))
pred
pred <- predict(train, testSA)
pred
pred <- predict(train, trainSA)
train$pred
train$results
missClass(factor(trainSA$chd), pred)
factor(trainSA$chd)
pred
missClass(trainSA$chd, pred)
missClass(trainSA$chd, numeric(pred))
missClass(trainSA$chd, as.numeric(pred,))
missClass(trainSA$chd, as.numeric(pred))
1 - missClass(trainSA$chd, as.numeric(pred))
train <- train(chd ~ age + alcohol + obesity + tobacco +typea + ldl,
data = trainSA,
method = "glm",
family = "binomial")
pred <- predict(train, trainSA)
missClass(trainSA$chd, pred)
# TEST SET
pred <- predict(train, testSA)
missClass(testSA, pred)
missClass(testSA$chd, pred)
# TRAINING SET
pred <- predict(train, trainSA)
missClass(trainSA$chd, pred)
# TEST SET
pred <- predict(train, testSA)
missClass(testSA$chd, pred)
# Q5.
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
rm(list = ls())
# Q5.
# Load the vowel.train and vowel.test data sets:
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
train <- train(y ~ .,
data = vowel.train,
method = "rf")
# ATTEMPT
set.seed(33833)
train <- train(y ~ .,
data = vowel.train,
method = "rf")
varImp(train)
varImp(train$finalModel)
varImp(train, useModel = "rf")
varImp(train$finalModel, useModel = "rf")
varImp(train, scale = FALSE)
train$finalModel
train <- train(y ~ .,
data = vowel.train,
method = "rf",
importance = TRUE,
verbose = TRUE,
prox = TRUE)
varImp(train)
train <- randomForest::randomForest(y ~ .,
data = vowel.train,
method = "rf",
importance = TRUE,
verbose = TRUE,
prox = TRUE)
varImp(train)
# ATTEMPT
library(randomForest)
train <- randomForest(y ~ .,
data = vowel.train,
method = "rf",
importance = TRUE,
verbose = TRUE,
prox = TRUE)
train <- randomForest(y ~ .,
data = vowel.train,
method = "rf")
varImp(train)
varImp(train, scale = FALSE)
train <- randomForest(y ~ .,
data = vowel.train,
method = "rf",
importance = TRUE,
verbose = TRUE,
prox = TRUE)
varImp(train, scale = FALSE)
train <- train(y ~ .,
data = vowel.train,
method = "rf",
importance = TRUE,
verbose = TRUE,
prox = TRUE)
varImp(train, scale = FALSE)
train <- train(factor(y) ~ .,
data = vowel.train,
method = "rf",
importance = TRUE,
verbose = TRUE,
prox = TRUE)
varImp(train, scale = FALSE)
varImp(train, decreasing = TRUE)
varImp(train[11], decreasing = TRUE)
varImp(train[, 11], decreasing = TRUE)
varImp(train$finalModel, decreasing = TRUE)
train
arrange(varImp(train$finalModel), decreasing = TRUE)
arrange(decreasing(varImp(train$finalModel)))
arrange(desc(varImp(train$finalModel)))
varImp(train, decreasing = TRUE)
varImp(train)
order(varImp(train), descending = TRUE)
order(varImp(train), decreasing = TRUE)
order(varImp(train$finalModel), decreasing = TRUE)
order(varImp(train$finalModel, scale = FALSE), decreasing = TRUE)
knit_with_parameters('~/Projects/Courses/Coursera/Practical Machine Learning/Human-Activity-Recognition/HumanActivityRecognition.Rmd')
plot7 <- plot.roc.curve.2("Ensemble Model", ensemble.confusion.matrix)
set.seed(11111)
library(dplyr)
library(caret)
library(ggplot2)
library(reshape2)
library(pROC)
library(MLmetrics)
library(gridExtra)
plot7 <- plot.roc.curve.2("Ensemble Model", ensemble.confusion.matrix)
# official
plot.roc.curve.2 <- function(model.name, train.and.predict.object) {
confusion.matrix <- train.and.predict.object$confusion.matrix
# Accuracy
out.of.sample.error <- train.and.predict.object$out.of.sample.error
by.class <- confusion.matrix$byClass[, c("Sensitivity",
"Specificity")]
p <- ggplot(x = NA, y = NA, xlim = c(0,1), ylim = c(0,1)) +
geom_line(aes(x = c(0, 1 - by.class[1, "Specificity"], 1),
y = c(0, by.class[1, "Sensitivity"], 1)),
colour = 2, lwd = 1) +
geom_line(aes(x = c(0, 1 - by.class[2, "Specificity"], 1),
y = c(0, by.class[2, "Sensitivity"], 1)),
colour = 3, lwd = 1) +
geom_line(aes(x = c(0, 1 - by.class[3, "Specificity"], 1),
y = c(0, by.class[3, "Sensitivity"], 1)),
colour = 4, lwd = 1) +
geom_line(aes(x = c(0, 1 - by.class[4, "Specificity"], 1),
y = c(0, by.class[4, "Sensitivity"], 1)),
colour = 5, lwd = 1) +
geom_line(aes(x = c(0, 1 - by.class[5, "Specificity"], 1),
y = c(0, by.class[5, "Sensitivity"], 1)),
colour = 6, lwd = 1) +
geom_line(aes(x = c(0, 1), y = c(0, 1))) +
labs(y = 'True Positive Rate',
x = 'False Positive Rate',
title = paste("ROC Curves Per Activity Class (", model.name, ")"),
subtitle = paste("Model has an Overall Out-of-Sample-Error of ",
out.of.sample.error))
p
}
plot1 <- plot.roc.curve.2("Decision Tree", decision.tree.confusion.matrix)
load("~/Projects/Courses/Coursera/Practical Machine Learning/Human-Activity-Recognition/cache/cache.data.RData")
plot6 <- plot.roc.curve.2("Neural Networks", neural.network.confusion.matrix)
freq.plot <- ggplot() +
suppressWarnings(geom_histogram(aes(x = as.numeric(test.pca$classe), fill = test.pca$classe),
stat = "count")) +
theme(legend.position = "bottom") +
scale_fill_manual(name = "Activity Classes", values = 2:6) +
labs(y = 'Frequency',
x = 'Activity Classes',
title = paste("Fig 3. Frequency Plot Per Activity Classes"))
# gets legend to be used in roc curves
get.legend <- function(a.gplot) {
tmp <- ggplot_gtable(ggplot_build(a.gplot))
leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
legend <- tmp$grobs[[leg]]
return(legend)
}
custom.legend <- get.legend(freq.plot)
grid.arrange(plot1, custom.legend, ncol = 1, nrow = 2, heights = c(10, 1))
grid.arrange(plot7, custom.legend, ncol = 1, nrow = 2, heights = c(10, 1))
grid.arrange(plot6, custom.legend, ncol = 1, nrow = 2, heights = c(10, 1))
plot.roc.curve <- function(model.name, confusion.matrix) {
# Accuracy
accuracy <- round(confusion.matrix$overall["Accuracy"], 2)
plot(x = NA, y = NA, xlim = c(0,1), ylim = c(0,1),
ylab = 'True Positive Rate',
xlab = 'False Positive Rate',
bty = 'n',
main = paste("ROC Curves Per Activity (", model.name, ")"),
sub = paste("Model has an Overall Accuracy of ", accuracy))
by.class <- confusion.matrix$byClass[, c("Sensitivity",
"Specificity")]
for(i in 1 : dim(by.class)[1]) {
x <- c(0, 1 - by.class[i, "Specificity"], 1)
y <- c(0, by.class[i, "Sensitivity"], 1)
lines(y ~ x, col= i + 1, lwd=2)
}
lines(x=c(0,1), c(0,1))
legend(x = "bottomright",
legend = c("Activity A",
"Activity B",
"Activity C",
"Activity D",
"Activity E"),
fill = 1 : dim(by.class)[1] + 1)
}
plot6 <- plot.roc.curve("Neural Networks", neural.network.confusion.matrix)
grid.arrange(plot6, custom.legend, ncol = 1, nrow = 2, heights = c(10, 1))
plot6
colnames(test.data.raw)
validation.pca <- predict(object = preprocess.pca,
newdata = subset(test.data.raw, select = -problem_id))
predict(object = nnet, newdata = validation.pca)
predict(object = svmpoly, newdata = validation.pca)
predict(object = svm.model, newdata = validation.pca)
str(validation.pca)
test.data.raw
subset(test.data.raw, select = -problem_id)
predict(object = preprocess.pca,
newdata = subset(test.data.raw, select = -problem_id))
colnames(predict(object = preprocess.pca,
newdata = subset(test.data.raw, select = -problem_id)))
test.data.reduced
unlabeled.data.pca <- predict(object = preprocess.pca,
newdata = subset(test.data.reduced, select = -problem_id))
predict(object = svm.model, newdata = unlabeled.data.pca)
unlabeled.data.pca
predict(object = svmpoly, newdata = unlabeled.data.pca)
?svmPoly
??svmPoly
unlink('Projects/Courses/Coursera/Practical Machine Learning/Human-Activity-Recognition/HumanActivityRecognition_cache', recursive = TRUE)
unlink('Projects/Courses/Coursera/Practical Machine Learning/Human-Activity-Recognition/HumanActivityRecognition_cache', recursive = TRUE)
set.seed(11111)
library(dplyr)
library(caret)
library(ggplot2)
library(reshape2)
library(pROC)
library(MLmetrics)
library(gridExtra)
# set working directory
setwd("~/Projects/Courses/Coursera/Practical Machine Learning/Human-Activity-Recognition/")
# read csv
train.data.raw <- read.csv(file = "data/pml-training.csv")
test.data.raw <- read.csv(file = "data/pml-testing.csv")
# Select columns with complete cases:
# class of each column in dataset
col.class <- sapply(train.data.raw, class)
# show unique classes
unique(col.class)
# check columns with an acceptable amount of values with complete cases
# (non-null and non-empty values)
# acceptability in this case means that the number of values in the column
# with complete cases is greater than or equal to 90% of the total observations
# in the dataset.
get.col.indexes.with.complete.cases <- function(data) {
data %>% sapply(function(x) {
if (is.numeric(x)) {
# for numeric columns
# check if a reasonable amount of values in the column have complete cases
# if yes, return true, else return false
if (sum(complete.cases(x)) >= (length(x) * 0.9)) {
TRUE
} else {
FALSE
}
} else {
# for factor columns
# check if reasonable amount of values in the columns have complete cases
# AND not equal to empty string
# if yes, return true, else return false
if (sum(complete.cases(x)) >= (length(x) * 0.9) &
sum(x != "") >= (length(x) * 0.9)) {
TRUE
} else {
FALSE
}
}
})
}
# reduced train dataset (columns with acceptably complete cases)
train.data.complete.cases.index <-
get.col.indexes.with.complete.cases(train.data.raw)
train.data.reduced <- train.data.raw[, train.data.complete.cases.index]
# removing unnecessary covariates
train.data.reduced[1:5, 1:5]
names(train.data.reduced[1:5, 1:5])
train.data.reduced[, -1:5]
train.data.reduced[, -c(1:5)]
# removing unnecessary covariates
train.data.reduced[1:5, 1:6]
# removing unnecessary covariates
train.data.reduced[1:5, 1:6]
train.data.reduced[, -c(1:6)]
# removing unnecessary covariates
train.data.reduced[1:5, 1:6]
train.data.reduced <- train.data.reduced[, -c(1:6)]
unlabeled.data.reduced <- unlabeled.data.reduced[, -c(1:6)]
# for 20 unlabeled observations
unlabeled.data.reduced <- test.data.raw[, train.data.complete.cases.index]
unlabeled.data.reduced <- unlabeled.data.reduced[, -c(1:6)]
unlabeled.data.reduced[1:5, ]
unlabeled.data.reduced
train.data.reduced <- train.data.reduced[, -c(1:6)]
train.data.reduced <- train.data.reduced[1:5, -c(1:6)]
train.data.reduced
unlabeled.data.reduced <- unlabeled.data.reduced[, -c(1:7)]
unlabeled.data.reduced
# read csv
train.data.raw <- read.csv(file = "data/pml-training.csv")
test.data.raw <- read.csv(file = "data/pml-testing.csv")
# Select columns with complete cases:
# class of each column in dataset
col.class <- sapply(train.data.raw, class)
# show unique classes
unique(col.class)
# check columns with an acceptable amount of values with complete cases
# (non-null and non-empty values)
# acceptability in this case means that the number of values in the column
# with complete cases is greater than or equal to 90% of the total observations
# in the dataset.
get.col.indexes.with.complete.cases <- function(data) {
data %>% sapply(function(x) {
if (is.numeric(x)) {
# for numeric columns
# check if a reasonable amount of values in the column have complete cases
# if yes, return true, else return false
if (sum(complete.cases(x)) >= (length(x) * 0.9)) {
TRUE
} else {
FALSE
}
} else {
# for factor columns
# check if reasonable amount of values in the columns have complete cases
# AND not equal to empty string
# if yes, return true, else return false
if (sum(complete.cases(x)) >= (length(x) * 0.9) &
sum(x != "") >= (length(x) * 0.9)) {
TRUE
} else {
FALSE
}
}
})
}
# reduced train dataset (columns with acceptably complete cases)
train.data.complete.cases.index <-
get.col.indexes.with.complete.cases(train.data.raw)
train.data.reduced <- train.data.raw[, train.data.complete.cases.index]
# for 20 unlabeled observations
unlabeled.data.reduced <- test.data.raw[, train.data.complete.cases.index]
# removing unnecessary covariates
train.data.reduced[1:5, 1:6]
unlabeled.data.reduced[1:5, ]
train.data.reduced[1:5, ]
unlabeled.data.reduced[1:5, ]
# reduced train dataset (columns with acceptably complete cases)
train.data.complete.cases.index <-
get.col.indexes.with.complete.cases(train.data.raw)
train.data.reduced <- train.data.raw[, train.data.complete.cases.index]
# for 20 unlabeled observations
unlabeled.data.reduced <- test.data.raw[, train.data.complete.cases.index]
# removing unnecessary covariates
train.data.reduced[1:5, 1:7]
train.data.reduced <- train.data.reduced[, -c(1:7)]
unlabeled.data.reduced <- unlabeled.data.reduced[, -c(1:7)]
train.data.reduced[1:5, ]
unlink('HumanActivityRecognition_cache', recursive = TRUE)
knitr::knit("./HumanActivityRecognition.Rmd", "./README.md")
knitr::knit("./README.Rmd", "./README.md")
getwd()
setwd("/home/arsenius/Projects/Courses/Coursera/Practical Machine Learning/Human-Activity-Recognition")
knitr::knit("./README.Rmd", "./README.md")
knitr::knit("./README.Rmd", "./README.md")
knitr::knit("./README.Rmd", "./README.md")
knitr::knit("./README.Rmd", "./README.md")
knitr::knit("./README.Rmd", "./README.md")
knitr::knit("./README.Rmd", "./README.md")
# Using ensemble model
ensemble.train <- data.frame(svm = gather.predictions(svmpoly$model)$predictions,
rforest = gather.predictions(rforest$model)$predictions,
classe = train.pca$classe)
